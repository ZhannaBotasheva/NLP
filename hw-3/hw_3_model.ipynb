{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b3373e",
   "metadata": {},
   "source": [
    "## HW 3\n",
    "Botasheva Zhanna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90acced",
   "metadata": {},
   "source": [
    "## Что в векторе твоем?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134092c9",
   "metadata": {},
   "source": [
    "### Цель:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a60639",
   "metadata": {},
   "source": [
    "В этом ДЗ вы освоите работу с предобученными векторными представлениями.\n",
    "В качестве данных возьмите либо датасет, собранный в первом занятии (предпочтительно), либо скачайте данные с отзывами на фильмы с сайта IMDB (https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews), в которых для каждого отзыва поставлена семантическая оценка - \"позитивный\" или \"негативный\".\n",
    "\n",
    "- Разбейте собранные данные на train/test, отложив 20-30% наблюдений для тестирования.\n",
    "Примените tf-idf преобразование для текстового описания. Используйте как отдельные токены, так и биграммы, отсейте стоп-слова, а также слова, которые встречаются слишком редко или слишком часто (параметры min/max_df), не забудьте убрать l2 регуляризацию, которая по умолчанию включена.\n",
    "- Обучите random forest или градиентный бустинг (LightGBM или catboost) на полученных векторах и подберите оптимальную комбинацию гиперпараметров с помощью GridSearch\n",
    "- Теперь воспользуйтесь предобученными word2vec/fasttext эмбеддингами для векторизации текста. Векторизуйте тексты с помощью метода word2vec/fasttext c весами tf-idf\n",
    "- Совет: для текстов на русском языке можно взять предобученные эмбеддинги с сайта rusvectores https://rusvectores.org/ru/models/ (вам подходят эмбеддинги с параметром тэгсет НЕТ). Для английского языка можете воспользоваться word2vec, обученными на Google News\n",
    "Повторите эксперимент из пункта 4 с использованием полученных в пункте 5 векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca174551",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da7df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk   # Natural Language Toolkit\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "171661d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('book.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "429e2bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Название книги</th>\n",
       "      <th>Автор</th>\n",
       "      <th>Рейтинг</th>\n",
       "      <th>ID</th>\n",
       "      <th>Год</th>\n",
       "      <th>Кол-во страниц</th>\n",
       "      <th>Цена</th>\n",
       "      <th>Описание</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Девушка Online</td>\n",
       "      <td>Сагг Зои</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7467401.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>Зои Сагг, известная как Zoella, - двадцатичеты...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Мятная сказка. Специальное издание</td>\n",
       "      <td>Полярный Александр</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7740488.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>«Мятная сказка» - культовая книга, принесшая с...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Реннвинд. Сердце тьмы</td>\n",
       "      <td>Стенберг Леа</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7965332.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>Когда кажется, что все секреты раскрыты, стано...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Трансформатор 3. В чем сила, бро?</td>\n",
       "      <td>Портнягин Дмитрий</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7769954.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Дмитрий Портнягин - известный российский предп...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Все это время</td>\n",
       "      <td>Дотри Микки</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7820141.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>Рейчел Липпинкотт, Микки Дотри — авторы, котор...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      Название книги               Автор  \\\n",
       "0           0                      Девушка Online            Сагг Зои   \n",
       "1           1  Мятная сказка. Специальное издание  Полярный Александр   \n",
       "2           2               Реннвинд. Сердце тьмы        Стенберг Леа   \n",
       "3           3   Трансформатор 3. В чем сила, бро?   Портнягин Дмитрий   \n",
       "4           4                       Все это время         Дотри Микки   \n",
       "\n",
       "   Рейтинг         ID     Год  Кол-во страниц   Цена  \\\n",
       "0      2.0  7467401.0  2020.0           352.0  375.0   \n",
       "1      2.0  7740488.0  2019.0           160.0  690.0   \n",
       "2      4.3  7965332.0  2023.0           384.0  440.0   \n",
       "3      1.5  7769954.0  2019.0           304.0  125.0   \n",
       "4      NaN  7820141.0  2020.0           384.0  360.0   \n",
       "\n",
       "                                            Описание   0  \n",
       "0  Зои Сагг, известная как Zoella, - двадцатичеты... NaN  \n",
       "1  «Мятная сказка» - культовая книга, принесшая с... NaN  \n",
       "2  Когда кажется, что все секреты раскрыты, стано... NaN  \n",
       "3  Дмитрий Портнягин - известный российский предп... NaN  \n",
       "4  Рейчел Липпинкотт, Микки Дотри — авторы, котор... NaN  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b6bb6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 473 entries, 0 to 472\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      473 non-null    int64  \n",
      " 1   Название книги  471 non-null    object \n",
      " 2   Автор           471 non-null    object \n",
      " 3   Рейтинг         233 non-null    float64\n",
      " 4   ID              471 non-null    float64\n",
      " 5   Год             471 non-null    float64\n",
      " 6   Кол-во страниц  469 non-null    float64\n",
      " 7   Цена            466 non-null    float64\n",
      " 8   Описание        471 non-null    object \n",
      " 9   0               2 non-null      float64\n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 37.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f61fad",
   "metadata": {},
   "source": [
    "Избавимся от Nan в Рейтинге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d9cd17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Рейтинг'] = df['Рейтинг'].fillna(0) \n",
    "df = df.dropna(subset=['Рейтинг'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af1247",
   "metadata": {},
   "source": [
    "Удалим лишние столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e744bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "03aee83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Название книги</th>\n",
       "      <th>Автор</th>\n",
       "      <th>Рейтинг</th>\n",
       "      <th>ID</th>\n",
       "      <th>Год</th>\n",
       "      <th>Кол-во страниц</th>\n",
       "      <th>Цена</th>\n",
       "      <th>Описание</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Девушка Online</td>\n",
       "      <td>Сагг Зои</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7467401.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>Зои Сагг, известная как Zoella, - двадцатичеты...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Мятная сказка. Специальное издание</td>\n",
       "      <td>Полярный Александр</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7740488.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>«Мятная сказка» - культовая книга, принесшая с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Реннвинд. Сердце тьмы</td>\n",
       "      <td>Стенберг Леа</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7965332.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>Когда кажется, что все секреты раскрыты, стано...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Трансформатор 3. В чем сила, бро?</td>\n",
       "      <td>Портнягин Дмитрий</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7769954.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Дмитрий Портнягин - известный российский предп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Злая лисица</td>\n",
       "      <td>Чо Кэт</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7841391.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>ЛУЧШЕЕ YOUNG ADULT ФЭНТЕЗИ 2021 ГОДА! ВПЕРВЫЕ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Название книги               Автор  Рейтинг         ID  \\\n",
       "0                      Девушка Online            Сагг Зои      2.0  7467401.0   \n",
       "1  Мятная сказка. Специальное издание  Полярный Александр      2.0  7740488.0   \n",
       "2               Реннвинд. Сердце тьмы        Стенберг Леа      4.3  7965332.0   \n",
       "3   Трансформатор 3. В чем сила, бро?   Портнягин Дмитрий      1.5  7769954.0   \n",
       "5                         Злая лисица              Чо Кэт      4.0  7841391.0   \n",
       "\n",
       "      Год  Кол-во страниц   Цена  \\\n",
       "0  2020.0           352.0  375.0   \n",
       "1  2019.0           160.0  690.0   \n",
       "2  2023.0           384.0  440.0   \n",
       "3  2019.0           304.0  125.0   \n",
       "5  2022.0           480.0  460.0   \n",
       "\n",
       "                                            Описание  \n",
       "0  Зои Сагг, известная как Zoella, - двадцатичеты...  \n",
       "1  «Мятная сказка» - культовая книга, принесшая с...  \n",
       "2  Когда кажется, что все секреты раскрыты, стано...  \n",
       "3  Дмитрий Портнягин - известный российский предп...  \n",
       "5  ЛУЧШЕЕ YOUNG ADULT ФЭНТЕЗИ 2021 ГОДА! ВПЕРВЫЕ ...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cf760",
   "metadata": {},
   "source": [
    "Для упрощения задачи добавим столбец \"Рекомендация\", чтобы использовать его в качестве целевой перемнной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1a7d7d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Название книги</th>\n",
       "      <th>Автор</th>\n",
       "      <th>Рейтинг</th>\n",
       "      <th>ID</th>\n",
       "      <th>Год</th>\n",
       "      <th>Кол-во страниц</th>\n",
       "      <th>Цена</th>\n",
       "      <th>Описание</th>\n",
       "      <th>Рекомендация</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Девушка Online</td>\n",
       "      <td>Сагг Зои</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7467401.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>Зои Сагг, известная как Zoella, - двадцатичеты...</td>\n",
       "      <td>Не рекомендуют</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Мятная сказка. Специальное издание</td>\n",
       "      <td>Полярный Александр</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7740488.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>«Мятная сказка» - культовая книга, принесшая с...</td>\n",
       "      <td>Не рекомендуют</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Реннвинд. Сердце тьмы</td>\n",
       "      <td>Стенберг Леа</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7965332.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>Когда кажется, что все секреты раскрыты, стано...</td>\n",
       "      <td>Рекомендуют</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Трансформатор 3. В чем сила, бро?</td>\n",
       "      <td>Портнягин Дмитрий</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7769954.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Дмитрий Портнягин - известный российский предп...</td>\n",
       "      <td>Не рекомендуют</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Злая лисица</td>\n",
       "      <td>Чо Кэт</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7841391.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>ЛУЧШЕЕ YOUNG ADULT ФЭНТЕЗИ 2021 ГОДА! ВПЕРВЫЕ ...</td>\n",
       "      <td>Рекомендуют</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Название книги               Автор  Рейтинг         ID  \\\n",
       "0                      Девушка Online            Сагг Зои      2.0  7467401.0   \n",
       "1  Мятная сказка. Специальное издание  Полярный Александр      2.0  7740488.0   \n",
       "2               Реннвинд. Сердце тьмы        Стенберг Леа      4.3  7965332.0   \n",
       "3   Трансформатор 3. В чем сила, бро?   Портнягин Дмитрий      1.5  7769954.0   \n",
       "5                         Злая лисица              Чо Кэт      4.0  7841391.0   \n",
       "\n",
       "      Год  Кол-во страниц   Цена  \\\n",
       "0  2020.0           352.0  375.0   \n",
       "1  2019.0           160.0  690.0   \n",
       "2  2023.0           384.0  440.0   \n",
       "3  2019.0           304.0  125.0   \n",
       "5  2022.0           480.0  460.0   \n",
       "\n",
       "                                            Описание    Рекомендация  \n",
       "0  Зои Сагг, известная как Zoella, - двадцатичеты...  Не рекомендуют  \n",
       "1  «Мятная сказка» - культовая книга, принесшая с...  Не рекомендуют  \n",
       "2  Когда кажется, что все секреты раскрыты, стано...     Рекомендуют  \n",
       "3  Дмитрий Портнягин - известный российский предп...  Не рекомендуют  \n",
       "5  ЛУЧШЕЕ YOUNG ADULT ФЭНТЕЗИ 2021 ГОДА! ВПЕРВЫЕ ...     Рекомендуют  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Рекомендация'] = df['Рейтинг'].apply(lambda x: 'Рекомендуют' if x >= 4 else 'Не рекомендуют')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b073fd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Рекомендация\n",
       "Рекомендуют       119\n",
       "Не рекомендуют    114\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Рекомендация'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20308442",
   "metadata": {},
   "source": [
    "Цеоевая переменная сбалансирована, возможно стоило спарсить больше данных, попробуем поработать с тем что есть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3200d2",
   "metadata": {},
   "source": [
    "Разобьем выборку на две части: тренировочную (train) и тестовую выборку (test). На test будем проверять обобщающая способность модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b1571d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train,X_test = tts(data_preprocessed,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b1f07322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренировачная выборка\n",
    "\n",
    "corpus_tr = list(X_train['Описание'])  # корпус \n",
    "target_tr = list(X_train['Рекомендация'])   # целевая функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "438da458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовая выборка\n",
    "\n",
    "corpus_te = list(X_test['Описание'])  # корпус \n",
    "target_te = list(X_test['Рекомендация'])   # целевая функция"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1b4b0d",
   "metadata": {},
   "source": [
    "### Варианты TF-IDF\n",
    "Все варианты преобразования документов в корпусе используя TF-IDF для создания векторного представления слов перечислены ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dc7fc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "# минимальная частота слов\n",
    "v1_vectoriser = TfidfVectorizer(min_df=3,norm=None)\n",
    "v1_vectoriser.fit(corpus_tr)\n",
    "X1 = v1_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v2_vectoriser = TfidfVectorizer(min_df=2,norm=None)\n",
    "v2_vectoriser.fit(corpus_tr)\n",
    "X2 = v2_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v3_vectoriser = TfidfVectorizer(min_df=1,norm=None)\n",
    "v3_vectoriser.fit(corpus_tr)\n",
    "X3 = v3_vectoriser.transform(corpus_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1f5b7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# стоп слова варианты\n",
    "v4_vectoriser = TfidfVectorizer(min_df=3,norm=None,stop_words=russian_stopwords)\n",
    "v4_vectoriser.fit(corpus_tr)\n",
    "X4 = v4_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v5_vectoriser = TfidfVectorizer(min_df=2,norm=None,stop_words=russian_stopwords)\n",
    "v5_vectoriser.fit(corpus_tr)\n",
    "X5 = v5_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v6_vectoriser = TfidfVectorizer(min_df=1,norm=None,stop_words=russian_stopwords)\n",
    "v6_vectoriser.fit(corpus_tr)\n",
    "X6 = v6_vectoriser.transform(corpus_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a2278747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# н-грам варианты\n",
    "v7_vectoriser = TfidfVectorizer(min_df=2,norm=None,stop_words=russian_stopwords,ngram_range=(1,1))\n",
    "v7_vectoriser.fit(corpus_tr)\n",
    "X7 = v7_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v8_vectoriser = TfidfVectorizer(min_df=2,norm=None,stop_words=russian_stopwords,ngram_range=(1,2))\n",
    "v8_vectoriser.fit(corpus_tr)\n",
    "X8 = v8_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v9_vectoriser = TfidfVectorizer(min_df=2,norm=None,stop_words=russian_stopwords,ngram_range=(1,3))\n",
    "v9_vectoriser.fit(corpus_tr)\n",
    "X9 = v9_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v10_vectoriser = TfidfVectorizer(min_df=2,norm=None,stop_words=russian_stopwords,ngram_range=(2,2))\n",
    "v10_vectoriser.fit(corpus_tr)\n",
    "X10 = v10_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v11_vectoriser = TfidfVectorizer(min_df=2,norm=None,stop_words=russian_stopwords,ngram_range=(3,3))\n",
    "v11_vectoriser.fit(corpus_tr)\n",
    "X11 = v11_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v12_vectoriser = TfidfVectorizer(min_df=2,norm=None,stop_words=russian_stopwords,ngram_range=(4,4))\n",
    "v12_vectoriser.fit(corpus_tr)\n",
    "X12 = v12_vectoriser.transform(corpus_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "12f8e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# максимальная частота слов\n",
    "v13_vectoriser = TfidfVectorizer(min_df=2,max_df=0.9,norm=None,stop_words=russian_stopwords)\n",
    "v13_vectoriser.fit(corpus_tr)\n",
    "X13 = v13_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v14_vectoriser = TfidfVectorizer(min_df=2,max_df=0.8,norm=None,stop_words=russian_stopwords)\n",
    "v14_vectoriser.fit(corpus_tr)\n",
    "X14 = v14_vectoriser.transform(corpus_tr)\n",
    "\n",
    "v15_vectoriser = TfidfVectorizer(min_df=2,max_df=0.7,norm=None,stop_words=russian_stopwords)\n",
    "v15_vectoriser.fit(corpus_tr)\n",
    "X15 = v15_vectoriser.transform(corpus_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53668c90",
   "metadata": {},
   "source": [
    "### Варианты Моделей\n",
    "\n",
    "Начнем с базового RandomForest (не очень глубокого) <code>model_srf</code>, а потом попробуем улучшить результат с помощью <code>model_drf</code> и <code>model_ocb</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "23421e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model_srf = RandomForestClassifier(n_estimators=10,random_state=32)  # не глубокий случайный лес\n",
    "model_drf = RandomForestClassifier(n_estimators=40,random_state=32)  # глубокий случайный лес\n",
    "model_ocb = CatBoostClassifier(silent=True)  # градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8104ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# вспомогательная функция для оценки модели\n",
    "\n",
    "def evaluate_tfidf(X,vect,name,model):\n",
    "\n",
    "    print(f'case_id: :{name}')\n",
    "    print('==================================')\n",
    "    \n",
    "    # train model\n",
    "    model.fit(X,target_tr)\n",
    "    y_model = model.predict(X)\n",
    "    print(f'train: {accuracy_score(target_tr,y_model)}')\n",
    "    \n",
    "    X = vect.transform(corpus_te)\n",
    "    y_model = model.predict(X)\n",
    "    print(f'test: {accuracy_score(y_model,target_te)}')\n",
    "    \n",
    "    print('==================================','\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e8766",
   "metadata": {},
   "source": [
    "### Минимальная частота слов\n",
    "\n",
    "Проверим как влияет фильтр минимальной частоты слов (<code>min_df</code>) в документе на результат \n",
    "- <code>v1</code> (<code>min_df=3</code> фильтруем слова которые появляются в документов меньше 3 раз)\n",
    "- <code>v2</code> (<code>min_df=2</code> фильтруем слова которые появляются в документов меньше 2 раз)\n",
    "- <code>v3</code> (<code>min_df=1</code> фильтруем слова которые появляются в документов меньше 1 раза)\n",
    "\n",
    "Как мы видим, эффект от фильтрации часто встречающихся слов разный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9558f279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :v3\n",
      "==================================\n",
      "train: 0.9546827794561934\n",
      "test: 0.6126760563380281\n",
      "================================== \n",
      "\n",
      "case_id: :v2\n",
      "==================================\n",
      "train: 0.972809667673716\n",
      "test: 0.5352112676056338\n",
      "================================== \n",
      "\n",
      "case_id: :v1\n",
      "==================================\n",
      "train: 0.9758308157099698\n",
      "test: 0.5985915492957746\n",
      "================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_tfidf(X3,v3_vectoriser,'v3',model_srf)\n",
    "evaluate_tfidf(X2,v2_vectoriser,'v2',model_srf)\n",
    "evaluate_tfidf(X1,v1_vectoriser,'v1',model_srf) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee7a31",
   "metadata": {},
   "source": [
    "### Стоп Слова\n",
    "\n",
    "- Попробуем повысить точность с помощью фильтрации не релевантных слов (стоп слова) \n",
    "- При использовании разных настроек <code>min_df</code> точность модели меняется по разному; <code>min_df=3</code> дает наиболее хороший результат\n",
    "\n",
    "Вариатны:\n",
    "- <code>v4</code> (фильтрация стоп слов с <code>min_df=3</code>)\n",
    "- <code>v5</code> (фильтрация стоп слов с <code>min_df=2</code>)\n",
    "- <code>v6</code> (фильтрация стоп слов с <code>min_df=1</code>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a3fe282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :v6\n",
      "==================================\n",
      "train: 0.9637462235649547\n",
      "test: 0.5492957746478874\n",
      "================================== \n",
      "\n",
      "case_id: :v5\n",
      "==================================\n",
      "train: 0.9667673716012085\n",
      "test: 0.5774647887323944\n",
      "================================== \n",
      "\n",
      "case_id: :v4\n",
      "==================================\n",
      "train: 0.9697885196374623\n",
      "test: 0.6267605633802817\n",
      "================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_tfidf(X4,v4_vectoriser,'v6',model_srf)\n",
    "evaluate_tfidf(X5,v5_vectoriser,'v5',model_srf)\n",
    "evaluate_tfidf(X6,v6_vectoriser,'v4',model_srf) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d6507",
   "metadata": {},
   "source": [
    "###  н-граммы\n",
    "\n",
    "- Вариант <code>v4</code> дает нам точность 0.63 на тестовой выборке, используем этот вариант и проверим разные комбинации н-грамм\n",
    "- Как мы видим, улучшении никаких нет на тестовой выборке, при использовании bigram,trigram, точность сильно снизилось,  базовые токены (unigram) являются критичным для высокой точности модели\n",
    "\n",
    "Варианты:\n",
    "\n",
    "- <code>v7</code> ngram_range=(1,1) (Только униграммы)\n",
    "- <code>v8</code> ngram_range=(1,2) (Униграммы и биграммы)\n",
    "- <code>v9</code> ngram_range=(1,3) (униграммы, биграммы и триграммы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "22c94d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :v9\n",
      "==================================\n",
      "train: 0.9697885196374623\n",
      "test: 0.6056338028169014\n",
      "================================== \n",
      "\n",
      "case_id: :v8\n",
      "==================================\n",
      "train: 0.9637462235649547\n",
      "test: 0.6126760563380281\n",
      "================================== \n",
      "\n",
      "case_id: :v7\n",
      "==================================\n",
      "train: 0.9667673716012085\n",
      "test: 0.5774647887323944\n",
      "================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_tfidf(X9,v9_vectoriser,'v9',model_srf)\n",
    "evaluate_tfidf(X8,v8_vectoriser,'v8',model_srf)\n",
    "evaluate_tfidf(X7,v7_vectoriser,'v7',model_srf) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fc2f37",
   "metadata": {},
   "source": [
    "Проверим еще варианты:\n",
    "\n",
    "- <code>v10</code> ngram_range=(1,1) (Только униграммы)\n",
    "- <code>v11</code> ngram_range=(2,2) (Только биграммы)\n",
    "- <code>v12</code> ngram_range=(3,3) (Только триграммы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "049491d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :v12\n",
      "==================================\n",
      "train: 0.6525679758308157\n",
      "test: 0.6267605633802817\n",
      "================================== \n",
      "\n",
      "case_id: :v11\n",
      "==================================\n",
      "train: 0.7250755287009063\n",
      "test: 0.6197183098591549\n",
      "================================== \n",
      "\n",
      "case_id: :v10\n",
      "==================================\n",
      "train: 0.9788519637462235\n",
      "test: 0.6197183098591549\n",
      "================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_tfidf(X12,v12_vectoriser,'v12',model_srf)\n",
    "evaluate_tfidf(X11,v11_vectoriser,'v11',model_srf)\n",
    "evaluate_tfidf(X10,v10_vectoriser,'v10',model_srf) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479ba26",
   "metadata": {},
   "source": [
    "### Максимальная частота\n",
    "\n",
    "В задании так же упоминается максимальная частота слов <code>max_df</code> в векторизаторе, попробуем варианты:\n",
    "- <code>v13</code> <code>max_df=0.9</code> (фильтруем слова которые появляются в 90% документов)\n",
    "- <code>v14</code> <code>max_df=0.8</code> (фильтруем слова которые появляются в 80% документов)\n",
    "- <code>v15</code> <code>max_df=0.7</code> (фильтруем слова которые появляются в 70% документов)\n",
    "\n",
    "Как мы видим, улучшении никаких нет, при уменьшении часто встречаюшихся слов, точность падает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f4f5cc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :v13\n",
      "==================================\n",
      "train: 0.9667673716012085\n",
      "test: 0.5774647887323944\n",
      "================================== \n",
      "\n",
      "case_id: :v14\n",
      "==================================\n",
      "train: 0.9667673716012085\n",
      "test: 0.5774647887323944\n",
      "================================== \n",
      "\n",
      "case_id: :v15\n",
      "==================================\n",
      "train: 0.9667673716012085\n",
      "test: 0.5774647887323944\n",
      "================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_tfidf(X13,v13_vectoriser,'v13',model_srf)\n",
    "evaluate_tfidf(X14,v14_vectoriser,'v14',model_srf)\n",
    "evaluate_tfidf(X15,v15_vectoriser,'v15',model_srf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05332dc2",
   "metadata": {},
   "source": [
    "### Выбор модели\n",
    "\n",
    "- Базовая модель случайного леса не очень глубокая, соответственно может не очень хорошо определить закономерности в данных, попробуем другие варианты перечислены в начале раздела\n",
    "- Воспользуемся вариантом который показал наилучшую обобщающию способность на тестовой выборке (<code>v4</code>)\n",
    "- CatBoost хорошо оптимизируется под любые табличные данные, и как мы видим улучшения нет, обе модели показывают примерно идентичный результат\n",
    "- Соответственно возможно что улучшении на тестовой выборке с TF-IDF (помимо токенизации) особо нет, и нужно проверить эмбеддинговый подход "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4596dbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 1775)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1775 признаков\n",
    "\n",
    "X4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "78c0cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :v4_deeprf\n",
      "==================================\n",
      "train: 0.9939577039274925\n",
      "test: 0.5915492957746479\n",
      "================================== \n",
      "\n",
      "case_id: :v4_catboost\n",
      "==================================\n",
      "train: 0.918429003021148\n",
      "test: 0.5915492957746479\n",
      "================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_tfidf(X4,v4_vectoriser,'v4_deeprf',model_drf)\n",
    "evaluate_tfidf(X4,v4_vectoriser,'v4_catboost',model_ocb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803530b0",
   "metadata": {},
   "source": [
    "### TF-IDF GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71254f32",
   "metadata": {},
   "source": [
    "- В ручную подборка гиперпараметров может оказаться не самым оптимальным вариантов, поэтому воспользуемся <code>GridSearchCV</code> методом кросс-валидации для подборки гиперпараметров модели\n",
    "- Какую конкретные параметры нужно оптимизировать не уточняется, попробуем найти более оптимальные параметры для модели случайного леса, так как CatBoost показал хуже результат\n",
    "\n",
    "У случайного леса много параметров которые можно перепобовать, ограничимся:\n",
    "- <code>max_depth</code> максимальная глубина разбиения \n",
    "- <code>n_estimators</code> количество решаущих деревьев\n",
    "- <code>criterion</code> критерии оценки разбиения в узле\n",
    "- <code>min_samples_leaf</code> минимальное количество образцов, необходимое для нахождения в листовом узле каждого дерева\n",
    "- <code>min_samples_split</code> Минимальное количество образцов, необходимое для разбиения внутреннего узла каждого дерева\n",
    "\n",
    "Из соображении времени, количество построенных деревьев ограничивается (e_stimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d19efc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import randint\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate_cv(X,name,base_estimator):\n",
    "\n",
    "    print(f'case_id: :{name}')\n",
    "    print('==================================')\n",
    "    \n",
    "    rs_space={'max_depth':list(np.arange(10,60,10)) + [None],\n",
    "              'n_estimators':np.arange(40,120, step=20),\n",
    "              'criterion':['gini','entropy'],\n",
    "              'min_samples_leaf':[1,2,3,4],\n",
    "               'min_samples_split':np.arange(2,6, step=2),\n",
    "              }\n",
    "\n",
    "    model = GridSearchCV(base_estimator,\n",
    "                         rs_space, \n",
    "                         scoring='accuracy', \n",
    "                         n_jobs=-1, \n",
    "                         cv=3)\n",
    "    \n",
    "    # train model\n",
    "    model.fit(X,target_tr)\n",
    "    \n",
    "    print('Best hyperparameters are: '+str(model.best_params_))\n",
    "    print('Best score is: '+str(model.best_score_))\n",
    "    \n",
    "    print('==================================','\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156558eb",
   "metadata": {},
   "source": [
    "Кросс валидация нам дает немного хуже результат чем на train/test разбиение; в итоге мы получаем **точность 0.63** на тестовой выборке в cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6d197d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :random_forest_cv\n",
      "==================================\n",
      "Best hyperparameters are: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 60}\n",
      "Best score is: 0.6345345345345346\n",
      "================================== \n",
      "\n",
      "CPU times: total: 3.81 s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_drf = RandomForestClassifier(random_state=32)\n",
    "evaluate_cv(X4,'random_forest_cv',model_srf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc00242",
   "metadata": {},
   "source": [
    "Проверим точность на на всей тестовой и отложенной тестовой выборке на больше объеме данных у нас модель показывает хуже результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "886f73f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :v4_rf_best\n",
      "==================================\n",
      "train: 0.972809667673716\n",
      "test: 0.5915492957746479\n",
      "================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = RandomForestClassifier(**{'criterion': 'entropy', \n",
    "                                     'max_depth': 40, \n",
    "                                     'min_samples_leaf': 3, \n",
    "                                     'min_samples_split': 2, \n",
    "                                     'n_estimators': 100, \n",
    "                                     'random_state':32})\n",
    "\n",
    "evaluate_tfidf(X4,v4_vectoriser,'v4_rf_best',best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb983187",
   "metadata": {},
   "source": [
    "### Эмбеддинги\n",
    "\n",
    "Для нашей задачи возьмем предобученные эмбеддинги (варианты без тагсет)\n",
    "- **geowac_lemmas_none_fasttextskipgram_300_5_2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "421df134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не забываем про веса tfidf; создадим словарь\n",
    "tfidf_weights = dict(zip(list(v4_vectoriser.vocabulary_.keys()),v4_vectoriser.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "25e49b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# название и URL\n",
    "we_models = {\"geowac_lemmas_none_fasttextskipgram_300_5_2020\": \"http://vectors.nlpl.eu/repository/20/213.zip\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "641ac860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем модель\n",
    "def get_models(model_url, model_name, path_to_save=\"C:\\\\Users\\\\Zhanna Botasheva\\\\Desktop\\\\\"):\n",
    "    model_path = path_to_save + model_name + \".zip\"\n",
    "    urllib.request.urlretrieve(model_url, model_path)\n",
    "\n",
    "for model_name, model_url in we_models.items():\n",
    "    get_models(model_url, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "467fc3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для чтения word2vec / FastText\n",
    "\n",
    "def open_model(model_name,model_path, is_fasttext = True):\n",
    "    \n",
    "    # word2vec (model.bin)\n",
    "    if is_fasttext == False:\n",
    "        model_file = model_path + model_name + \".zip\"\n",
    "        with zipfile.ZipFile(model_file, 'r') as archive:\n",
    "            stream = archive.open('model.bin')\n",
    "            model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)\n",
    "            \n",
    "    # fasttext (model.model)\n",
    "    else:\n",
    "        model_file = model_path + model_name\n",
    "        model = gensim.models.KeyedVectors.load(model_file + \"/model.model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d919459",
   "metadata": {},
   "source": [
    "Распакуем эмбеддинги и загружаем вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ed86d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"C:\\\\Users\\\\Zhanna Botasheva\\\\Desktop\\\\geowac_lemmas_none_fasttextskipgram_300_5_2020.zip\", 'r') as zip_ref: \n",
    "    zip_ref.extractall(\"C:\\\\Users\\\\Zhanna Botasheva\\\\Desktop\\\\geowac_lemmas_none_fasttextskipgram_300_5_2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0d9cd2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем KeyedVectors эмбеддинговый вектора \n",
    "geowac_model = open_model('geowac_lemmas_none_fasttextskipgram_300_5_2020','C:\\\\Users\\\\Zhanna Botasheva\\\\Desktop\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf435c",
   "metadata": {},
   "source": [
    "### Токенизация документов\n",
    "\n",
    "- Токенизируем все документы в тренировочной выборке/копрусе, будем использовать стандартный метод из nltk <code>word_tokenize</code>\n",
    "- Токенизированные документы сохраним в <code>lst_corpus_tr</code> и <code>lst_corpus_te</code> для <code>train</code> и <code>test</code> выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7a71fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Preprocessing, returns list instead\n",
    "def tokenise_for_word2vec(text):\n",
    "    \n",
    "    text = text.lower() #changes to lower case\n",
    "    tokens = word_tokenize(text) #tokenize the text\n",
    "    \n",
    "    clean_list = [] \n",
    "    for token in tokens:\n",
    "        clean_list.append(token)\n",
    "        \n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "eb37eaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Zhanna\n",
      "[nltk_data]     Botasheva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Загрузка необходимых ресурсов\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5dfb78e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_corpus_tr = []\n",
    "for doc in corpus_tr:\n",
    "    lst_corpus_tr.append(tokenise_for_word2vec(doc))\n",
    "    \n",
    "lst_corpus_te = []\n",
    "for doc in corpus_te:\n",
    "    lst_corpus_te.append(tokenise_for_word2vec(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fb3f3d",
   "metadata": {},
   "source": [
    "### Усредненные Вектора (без TF-IDF весов)\n",
    "\n",
    "- Воспользуемся самым простым подходом; для каждого документа мы возьмем **усредненный эмбеддинговый вектор** всех слов которые в него входят\n",
    "- Размерность данных с эмбеддингами получается намного ниже (300) чем в TF-IDF (1775) что должно сказаться на скорости обучения модели\n",
    "- Сохраняем эмбеддинг для каждого документа в <code>X_tr</code> и <code>X_te</code> для <code>train</code> и <code>test</code> выборки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "27c2744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average embedding vector for each text\n",
    "\n",
    "def doc_vectoriser(doc, model):\n",
    "    \n",
    "    doc_vector = []\n",
    "    num_words = 0\n",
    "    \n",
    "    for word in doc:\n",
    "        try:\n",
    "            if num_words == 0:\n",
    "                doc_vector = model[word]\n",
    "            else:\n",
    "                doc_vector = np.add(doc_vector, model[word])\n",
    "            num_words += 1\n",
    "        except:\n",
    "            pass  # if embedding vector isn't found\n",
    "     \n",
    "    return np.asarray(doc_vector) / num_words\n",
    "\n",
    "\n",
    "def doc_vectoriser(doc, model):\n",
    "    doc_vector = np.zeros((300,))  # Предполагаем, что размерность эмбеддингов 300\n",
    "    num_words = 0\n",
    "    \n",
    "    for word in doc:\n",
    "        if word in model:\n",
    "            doc_vector = np.add(doc_vector, model[word])\n",
    "            num_words += 1\n",
    "            \n",
    "    # Избегаем деления на ноль\n",
    "    return doc_vector / num_words if num_words > 0 else doc_vector\n",
    "\n",
    "X_tr = np.array([doc_vectoriser(doc, geowac_model) for doc in lst_corpus_tr])\n",
    "X_te = np.array([doc_vectoriser(doc, geowac_model) for doc in lst_corpus_te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0ec89ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = []\n",
    "for doc in lst_corpus_tr:\n",
    "    X_tr.append(doc_vectoriser(doc,geowac_model))\n",
    "    \n",
    "\n",
    "X_te = []\n",
    "for doc in lst_corpus_te:\n",
    "    X_te.append(doc_vectoriser(doc,geowac_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899ac06",
   "metadata": {},
   "source": [
    "### Усредненные Вектора (c TF-IDF весами)\n",
    "\n",
    "- Мы сохранили веса значимости слов (токенов) в документах корпуса в <code>tfidf_weights</code>\n",
    "- Сохраняем взвешенные эмбеддинг для каждого документа в <code>Xw_tr</code> и <code>Xw_te</code> для <code>train</code> и <code>test</code> выборки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fab0359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average embedding vector for each text \n",
    "\n",
    "def doc_vectoriser_tfidf(doc, model):\n",
    "    doc_vector = np.zeros((300,))  # Предполагаем, что размерность эмбеддингов 300\n",
    "    num_words = 0\n",
    "    \n",
    "    for word in doc:\n",
    "        if word in model:\n",
    "            if word in tfidf_weights:\n",
    "                doc_vector = np.add(doc_vector, model[word] * tfidf_weights[word])\n",
    "            else:\n",
    "                doc_vector = np.add(doc_vector, model[word])\n",
    "            num_words += 1\n",
    "            \n",
    "    return doc_vector / num_words if num_words > 0 else doc_vector\n",
    "\n",
    "Xw_tr = np.array([doc_vectoriser_tfidf(doc, geowac_model) for doc in lst_corpus_tr])\n",
    "Xw_te = np.array([doc_vectoriser_tfidf(doc, geowac_model) for doc in lst_corpus_te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4f6c8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xw_tr = []\n",
    "for doc in lst_corpus_tr:\n",
    "    Xw_tr.append(doc_vectoriser_tfidf(doc,geowac_model))\n",
    "    \n",
    "Xw_te = []\n",
    "for doc in lst_corpus_te:\n",
    "    Xw_te.append(doc_vectoriser_tfidf(doc,geowac_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b6abd",
   "metadata": {},
   "source": [
    "###  Варианты Моделей\n",
    "\n",
    "Повторим то что мы делали в части I:\n",
    "\n",
    "- В плане моделей, попробуем два подхода ансаблья, случайный лес (который использует бэггинт и метод случайного пространства) и градиентный бустинг СatBoost \n",
    "- Начнем с базового RandomForest (не очень глубокого) <code>model_srf</code>, а потом попробуем улучшить результат с помошью <code>model_drf</code> и <code>model_ocb</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "22fed1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model_srf = RandomForestClassifier(n_estimators=10,random_state=32)\n",
    "model_drf = RandomForestClassifier(n_estimators=40,random_state=32)\n",
    "model_ocb = CatBoostClassifier(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fada127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Импортируем матричу фич (эмбеддинги) X_tr, X_te\n",
    "# target_tr, target_te глоб \n",
    "\n",
    "def evaluate_embedding(X_tr, X_te, name, model):\n",
    "    print(f'case_id: :{name}')\n",
    "    print('==================================')\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        model.fit(X_tr, target_tr)\n",
    "        y_model_train = model.predict(X_tr)\n",
    "        print(f'train: {accuracy_score(target_tr, y_model_train)}')\n",
    "        \n",
    "        y_model_test = model.predict(X_te)\n",
    "        print(f'test: {accuracy_score(y_model_test, target_te)}')\n",
    "    except Exception as e:\n",
    "        print(f'Error during training or evaluation: {e}')\n",
    "        \n",
    "    print('==================================\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be58017",
   "metadata": {},
   "source": [
    "### Варианты Моделей (c TF-IDF весами)\n",
    "\n",
    "- Модели **с TF-IDF весами** для эмбеддингов\n",
    "- Точность с весами не улучшилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b1f8a8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :geowac_rf\n",
      "==================================\n",
      "train: 0.9939577039274925\n",
      "test: 0.5774647887323944\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_embedding(X_tr,X_te,'geowac_rf',model_drf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fcbe8bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :geowac_cat\n",
      "==================================\n",
      "train: 0.9939577039274925\n",
      "test: 0.6267605633802817\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_embedding(X_tr,X_te,'geowac_cat',model_ocb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3c4c8fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :geowac_rf_tfidf_weights\n",
      "==================================\n",
      "train: 0.9939577039274925\n",
      "test: 0.6338028169014085\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_embedding(Xw_tr,Xw_te,'geowac_rf_tfidf_weights',model_drf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9b9953fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :geowac_cat_tfidf_weights\n",
      "==================================\n",
      "train: 0.9939577039274925\n",
      "test: 0.6197183098591549\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_embedding(Xw_tr,Xw_te,'geowac_cat_tfidf_weights',model_ocb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c722c",
   "metadata": {},
   "source": [
    "### GridSearchCV (без TF-IDF весов)\n",
    "\n",
    "- Воспользуемся той же функции что и раньше для того чтобы оптимизировать гиперпараметры модели\n",
    "- Будем использовать случайны лес, и найдем наилучшие гиперпараметры используя кросс-валидацию <code>GridSearchCV</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bf21e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :geowac_rf_cv\n",
      "==================================\n",
      "Best hyperparameters are: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 40}\n",
      "Best score is: 0.6343707343707344\n",
      "================================== \n",
      "\n",
      "CPU times: total: 1.72 s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_drf = RandomForestClassifier(random_state=32)\n",
    "evaluate_cv(np.array(X_tr),'geowac_rf_cv',model_drf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1fc8d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_rf = RandomForestClassifier(**{'criterion': 'entropy', \n",
    "                                       'max_depth': 10, \n",
    "                                       'min_samples_leaf': 1, \n",
    "                                       'min_samples_split': 4, \n",
    "                                       'n_estimators': 100,\n",
    "                                       'random_state':32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2027bd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :geowac_rf_tfidf_weights\n",
      "==================================\n",
      "train: 0.9939577039274925\n",
      "test: 0.6056338028169014\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_embedding(X_tr,X_te,'geowac_rf_tfidf_weights',best_model_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aad690",
   "metadata": {},
   "source": [
    "### GridSearchCV (c TF-IDF весами)\n",
    "\n",
    "- Повторяем оптимизацию гиперпараметров для эмбеддингов с весами TF-IDF\n",
    "- Умножив веса из TF-IDF на эмбеддинги модель не много улучшилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2ac5b794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id: :geowac_rf_cv_tfidf_weights\n",
      "==================================\n",
      "Best hyperparameters are: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 80}\n",
      "Best score is: 0.6526344526344526\n",
      "================================== \n",
      "\n",
      "CPU times: total: 1.95 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_drf = RandomForestClassifier(random_state=32)\n",
    "evaluate_cv(np.array(Xw_tr),'geowac_rf_cv_tfidf_weights',model_drf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ba7739",
   "metadata": {},
   "source": [
    "Использование TF-IDF с Random Forest действительно показывает небольшое улучшение как в точности, так и в устойчивости модели. Это может быть связано с тем, что TF-IDF фокусирует внимание на более значимых словах для каждого документа, придавая им больший вес в расчёте вектора. Хотя точность модели увеличивается при использовании TF-IDF, улучшение незначительное, что может указывать на то, что вектора эмбеддингов уже улавливают важные характеристики текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f7a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
